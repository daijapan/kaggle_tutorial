{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このノートブックではpythonによるtitanicデータ処理の基本を勉強していきます。<br>\n",
    "ではまずpandasというデータ処理用のライブラリを用いてデータを読み込んでみましょう。<br>\n",
    "pythonではライブラリを読み込むときにimportもしくはfromを用います。<br>\n",
    "ではpandasを読み込んでみましょう。<br>\n",
    "このノートブックではtitanic_datasフォルダにデータがあると仮定して進めます。kaggleのkernelを使用している場合、データは../input/にあるのでデータのパスをtitanic_darasから../inputに変更してください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "read_data = pandas.read_csv(\"titanic_datas/train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "無事にデータを読み込むことはできたでしょうか？できたか確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "read_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "もしうまく読み込めていたら表のようなものが出力されていると思います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "titanicではどのような人が優先的に救助されたのでしょうか？<br>\n",
    "おそらく、レディーファーストで女性で若い人が優先されて救助されたのは間違いないでしょう。では生存率を見てみましょう、実際にそうだったのでしょうか。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "male_data = read_data[read_data.Sex == \"male\"]\n",
    "print(len(male_data[male_data.Survived == 1]) / len(male_data))\n",
    "\n",
    "female_data = read_data[read_data.Sex == \"female\"]\n",
    "print(len(female_data[female_data.Survived == 1]) / len(female_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これから女性の生存率がはるかに高いことがわかります。<br>\n",
    "ではほかの要素はどうでしょうか？例えば年齢などは関係してくるのでしょうか？<br>\n",
    "では試しにグラフを書いてみましょう。<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "split_data = []\n",
    "for survived in [0,1]:\n",
    "    split_data.append(read_data[read_data.Survived==survived])\n",
    "\n",
    "temp = [read_data.Age.dropna() for i in split_data]\n",
    "plt.hist(temp, histtype=\"barstacked\", bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "グラフだと若いと生存率が高いように見えます。本当でしょうか、割合を見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "read_data.Age.fillna(read_data.Age.median(), inplace=True)\n",
    "age_list = list(set(map(int, read_data.Age)))\n",
    "age_list.sort()\n",
    "age_per = list()\n",
    "for i in age_list:\n",
    "    age_data = read_data[read_data.Age == i]\n",
    "    if len(age_data) != 0:\n",
    "        age_per.append(len(age_data[age_data.Survived == 1]) / len(age_data))\n",
    "        print(i, len(age_data[age_data.Survived == 1]) / len(age_data))\n",
    "    else:\n",
    "        age_per.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "では、これを折れ線グラフにしてみましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(age_list, age_per)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このグラフから年齢が低い、もしくは高い人の生存率が高いことがわかります。<br>\n",
    "ここまでで、性別および年齢と生存率の相関がわかりました。以下では性別、年齢、社会的階級が生存と関係していたとかていして話を進めます。\n",
    "では各変数と生存率の相関を見るのはここまでにして、データの解析を行っていきましょう。\n",
    "\n",
    "今回、このノートブックではランダムフォレストとサポートベクトルマシンの仕組みおよび実装の説明をしていきたいと思います。<br>\n",
    "最初にランダムフォレストのもととなる決定木という手法について説明と実装をおこなっていきたいとおもいます。<br>\n",
    "決定木はかんたんに言うと、データをもとにデータを分類するルールを作っていく手法です。<br>\n",
    "ではどのようにして分類するルールを決定しているのでしょうか？それを今から見ていきましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "物事を決定するとき、決定しやすい情報がほしいと思います。<br>\n",
    "\n",
    "例えば、政治家といわれるとその情報だけでどの政治家か断定するのは難しいでしょう。しかし、これが大統領だとどうでしょう、一気に候補に挙がる人が少なくなることがわかります。<br>\n",
    "このように得た情報によって物事の決定のしやすさが大きく変わったと思います。<br>\n",
    "\n",
    "このように人間のように物事を決定できたら楽なのですが、コンピュータは計算ぐらいしかできないのでどうにかしてこれらの「情報の大きさ」というものを数学的に表す必要があります。<br>\n",
    "実はこのようなものを表すのに最適な数学の道具があります。それが情報量です。<br>\n",
    "\n",
    "情報量Iはつぎのように定義される量です。\n",
    "\\begin{equation*}\n",
    "I = -log P(x)\n",
    "\\end{equation*}\n",
    "ここでP(x)はxが起きた時の確率を表しています。<br>\n",
    "何故このような式になるのかは、深く考えないようにしてください。「あぁ、数学ではこのように情報の大きさを表しているんだな」というだけで十分です。\n",
    "\n",
    "情報量はある物事が起きた時に得られる情報の大きさを表しています。しかし、ここでほしいのは「一回情報を得たときに得られる情報の期待値を最小にする物事」です。<br>\n",
    "なぜこれを最小にしたいかというと、例えば先ほどの例を考えると政治家の母数よりも大統領の母数のほうが少ないですよね？このような情報では当然得られる情報量は少ないでしょう。つまり情報量が少なくなるように情報を選ぶと、少ない回数で物事を決定できることがわかります。<br>\n",
    "では一回に得られる情報量の期待値とはどのように計算したら良いでしょうか。\n",
    "\n",
    "ここで一度期待値を思い出してみましょう。<br>\n",
    "期待値を覚えていますか？覚えていない方もいるかもしれませんが大丈夫です、これから覚えましょう。<br>\n",
    "期待値Eとはある事象Xに対する確率P(X)とある事象Xに対応する関数の値f(X)に対して\n",
    "\\begin{equation*}\n",
    "E= \\sum_{X}^{}P(X)f(X)\n",
    "\\end{equation*}\n",
    "で表せる量です。<br>\n",
    "これは一回物事が起きた時に得られる平均のf(X)の値を表しています。<br>\n",
    "\n",
    "つまりこれに先ほどの情報量の定義式を入れれば一回に得られる平均の情報量Hがわかることになります。したがって\n",
    "\\begin{equation*}\n",
    "H = \\sum_{X}^{} -P(X)log P(X)\n",
    "\\end{equation*}\n",
    "これを平均情報量(エントロピー)といいます。\n",
    "\n",
    "ではまずエントロピーを計算する関数を作ってみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def entropy(probabilities):\n",
    "    return sum(-p * math.log(p,2) for p in probabilities if p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "どうでしょうか？この関数はただ式をプログラムにするだけなので難しくなかったと思います。難しかったという方も大丈夫、僕もこれを書くとき悩みましたから。<br>\n",
    "このプログラムでは確率を用います。なのでデータからあるデータが出てくる確率を計算する関数を作ってみましょう。<br>\n",
    "ここで注意が必要で、確率の総和は1でなければなりません。ここだけは注意してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def probabilities(labels):\n",
    "    total_count = len(labels)\n",
    "    return [count / total_count for count in Counter(labels).values()]   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これもそこまで難しくないと思います。ただし、Counterというクラスを使用しています。これは組み込み型でPythonで集計などをするとき便利な型なので覚えておくといいかもしれません。\n",
    "\n",
    "ここまででエントロピーを計算する関数と確率を計算するプログラムができました。次にデータを受け取り、そのデータから各データのエントロピーを計算するプログラムを書いてみましょう。\n",
    "ここではひとまずデータの構造はtuple型で最初にデータ、次に答えが来るようなtuple型のlistを仮定します。\n",
    "\n",
    "    [\n",
    "    (data, answer),\n",
    "    (data, answer),\n",
    "    ...\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_entropy(labeled_data):\n",
    "    labels = [label for _, label in labeled_data]\n",
    "    p = probabilities(labels)\n",
    "    return entropy(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "では次に分割されたデータのエントロピーを計算しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def partition_entropy(subsets):\n",
    "    total_count = sum(len(subset) for subset in subsets)\n",
    "    return sum(data_entropy(subset) * len(subset) / total_count for subset in subsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "では次にデータを与えられたキーで分割する関数を作ってみましょう。<br>\n",
    "ここで与えられたキーに対応するデータを出力のdictのキーとします。つまり<br>\n",
    "\n",
    "    [\n",
    "        {1:2, 2:3}\n",
    "        {1:3, 2:6}\n",
    "        {1:2, 2:5}\n",
    "    ]\n",
    "    \n",
    "というデータが与えられたとき、この関数にキーである1を与えると<br>\n",
    "\n",
    "    {\n",
    "    2:[{1:2, 2:3}, {1:2, 2:5}],\n",
    "    4:[{1:3, 2:6}],\n",
    "    }\n",
    "    \n",
    "などと帰ってくる関数です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def partition_by(inputs, attribute):\n",
    "    groups = dict()\n",
    "    for input in inputs:\n",
    "        key = input[0][attribute]\n",
    "        if not key in groups:\n",
    "            groups[key] = list()\n",
    "        groups[key].append(input)\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここまでで、分割されたデータのエントロピーの計算、データの分割まで関数を作成しました。<br>\n",
    "次に与えられたキーでデータを分割し、分割したデータのエントロピーを計算する関数を作ってみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcurate_entropy(inputs, attribute):\n",
    "    partitions = partition_by(inputs, attribute)\n",
    "    #print(partitions.values())\n",
    "    return partition_entropy(partitions.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ではこれらはきちんと動くのでしょうか？<br>\n",
    "実際に年齢と性別のエントロピーを計算して確認してみましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "import math\n",
    "\n",
    "data_key =[\"Age\",\"Sex\",\"Pclass\"]\n",
    "\n",
    "train = [({key:read_data.T[index][key] for key in data_key}, read_data.T[index][\"Survived\"]) for index in read_data.T]\n",
    "\n",
    "for key in data_key:\n",
    "    print(key, calcurate_entropy(train, key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "何らかの値が計算できたと思います。<br>\n",
    "最初に書いてあるように、エントロピーが最小になるようにルールを決定したらよいので、この場合最初に性別で分けるのが良いことがわかります。\n",
    "\n",
    "ここまでで、ルールを決定する方法を説明しました。<br>\n",
    "しかしこれらのルールをいちいち計算して、人間の手で作成していくのは非効率的です。<br>\n",
    "なのでルールを自動的に計算する関数を再帰を使って作りましょう。\n",
    "\n",
    "手順としては、まずデータ数、Survivedが1であるデータ数、Survivedが0であるデータ数を計算します。<br>\n",
    "\n",
    "Survivedが0,1であるデータ数のどちらかが0になったとき、データが決定されるので、ここでそのルールの生成を止めます。<br>\n",
    "もしsplit_candidatesがFalseの場合、つまり分割の候補がない場合、より多いデータを返します。\n",
    "\n",
    "それ以外の時、最小のエントロピーを持つキーでルールを生成したらよいので、最小のエントロピーを持つキーを計算します。<br>\n",
    "そして、その最小のキーの中に存在するデータを分割し、分割したデータをもとに、そのデータからさらにルールの生成などを再帰的に行うことで自動生成ができます。<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def build_tree(inputs, split_candidates=None):\n",
    "    if split_candidates is None:\n",
    "        split_candidates = inputs[0][0].keys()\n",
    "    \n",
    "    num_inputs = len(inputs)\n",
    "    num_1 = len([label for item, label in inputs if label == 1])\n",
    "    num_0 = num_inputs - num_1\n",
    "    \n",
    "    if num_1 == 0:\n",
    "        return 0\n",
    "    if num_0 == 0:\n",
    "        return 1\n",
    "    if not split_candidates:\n",
    "        return 1 if num_1 >= num_0 else 0\n",
    "    \n",
    "    best_attribute = min(split_candidates, key=partial(calcurate_entropy, inputs))\n",
    "    \n",
    "    partitions = partition_by(inputs, best_attribute)\n",
    "    new_candidates = [a for a in split_candidates if a != best_attribute]\n",
    "    \n",
    "    sub_trees = {attribute_value : build_tree(subset, new_candidates) for attribute_value, subset in partitions.items()}\n",
    "    sub_trees[None] = 1 if num_1 > num_0 else 0\n",
    "    \n",
    "    return best_attribute, sub_trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "では決定木を作ってみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree = build_tree(train)\n",
    "tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ではこれをもとにデータを分類してみたいと思います。\n",
    "そのために分類木とデータからデータを分類する関数を作ってみましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify(tree, input):\n",
    "    if tree in [0, 1]:\n",
    "        return tree\n",
    "    \n",
    "    attribute, subtree_dict = tree\n",
    "    subtree_key = input.get(attribute)\n",
    "    \n",
    "    if not subtree_key in subtree_dict:\n",
    "        subtree_key = None\n",
    "    \n",
    "    subtree = subtree_dict[subtree_key]\n",
    "    return classify(subtree, input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この関数にデータを入れたいと思います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "read_test_data = pandas.read_csv(\"titanic_datas/test.csv\")\n",
    "\n",
    "input_data = [{key:read_data.T[index][key] for key in data_key} for index in read_data.T]\n",
    "result = [classify(tree, input_data[i]) for i in range(len(read_test_data))]\n",
    "\n",
    "read_test_data[\"Survived\"] = result \n",
    "read_test_data[[\"PassengerId\",\"Survived\"]].to_csv(\"titanic_datas/submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここまでで、提出用のデータまで作成することができました。<br>\n",
    "しかし、提出はちょっと待ってください。これを提出しても0.55くらいのスコアしか出ません。<br>\n",
    "なぜかというと、この学習したデータのみに適応した決定木が作成されているためです。<br>\n",
    "これに対してどのように対処したらよいでしょうか？\n",
    "\n",
    "実はこれに対応するために作られたアルゴリズムがあります、それがランダムフォレストです。<br>\n",
    "ではランダムフォレストはどのように実装したらよいでしょうか？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
